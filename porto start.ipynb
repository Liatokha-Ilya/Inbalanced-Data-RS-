{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification. Linear models and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Porto Seguroâ€™s Safe Driver Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year.\n",
    "Read the detailed description and download the dataset https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data. Put the data into *./data/porto/*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Our model gets ~0.963 accuracy! But is it really good?...\n",
    "\n",
    "Let's plot the confusion matrix and analyze the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.5 points)** Prove that the **Normalized Gini Coefficient** is equivalent to **2 x AUC - 1** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, the proof will be launched from the geometrical perspective (since there are other ways to handle this using combinatorial methods). Also i have to mention - this is not analiticly true and approximatly true under some light assumptions. Lets begin.\n",
    "\n",
    "1. Gini coefficient computed by sorting predictions and then computing cumulative proportion of positive class observations to a theoretical uniform proportion (which is basicly an area under diogonal).\n",
    "\n",
    "2. If we think of ROC AUC, we can also gain an intuition that when we build ROC - we do it almost in the same way - by sorting predictions and moving right on negative class and up on positive one. Almost the same way as cumulative sum of positive class except \"corners\" (in Gini we move in 45' direction while meeting Positive class).\n",
    "\n",
    "3. Default gini coefficient in ml algorithms can not take the value of 1 because of its 45' direction moving. Even if all estimates will order the predictions in the right way, there still will be the area under curve to \"climb the stairs\" on positive classes. This is the reason why we should normalize our gini coefficient by dividing it by a Gini with the correct ordering (gini(a, a)).\n",
    "\n",
    "4. When we get normalized Gini, it will ranged in [0,1]. Just like the ROC AUC.\n",
    "\n",
    "5. Because of similarity in building Gini and ROC (we make an assumption that corners don't matter), we can conclude that while AUC = A+D, where D = area under diagonal, Gini = A/D. So basic math tells us: AUC = Gini*D + D. Since axis in ROC are normalized, D = 1\\2. So AUC = Gini/2 + D/2, which means Gini = 2Auc - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points)** By the way, what other metrics could you suggest for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suggest suicide \n",
    "\n",
    "I also suggest recall at first and then Harmonic Means with your custom betta (F score) since it is important to discover as much positive class cases as you can. And off course AUC since it is almost equivalent to gini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the Normalized Gini Coefficient:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 points + Y bonus points)** Try different approaches: oversampling / undersampling, careful feature analysis and feature engineering, etc., to get a reasonable pipeline and improve the model quality. Use cross-validation for model evaluation.\n",
    "\n",
    "Select the best model, load the test set and make the predictions. Submit them to kaggle.\n",
    "Y bonus points will be calculated as $\\frac{round(200 * \\max(score - 0.253, 0))}{2}$, where *score* is your kaggle leaderboard score.\n",
    "\n",
    "Note: do not use any classification models which have not been covered in the lessons yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link to my sulution with 0.26330 private score on kaggle:\n",
    "https://github.com/Liatokha-Ilya/Porto-RS/blob/main/Solving%20Porto.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.059999999999995\n"
     ]
    }
   ],
   "source": [
    "score = 0.26330\n",
    "score_Y = 200*max(score-0.253,0)\n",
    "print(score_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
